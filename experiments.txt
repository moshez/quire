Experiments log for ward#18 reproduction
========================================

GOAL: Find a standalone ATS2 reproduction of the Chromium renderer crash
that occurs during chapter navigation in quire with the conan EPUB.
See success.txt for success criteria.

KNOWN FACTS:
- Crash: "Target crashed" (Chromium renderer process death) on Next click
- Happens after: import EPUB, decompress metadata (2x), decompress TOC,
  decompress+render cover chapter (~21KB HTML, hundreds of DOM elements)
- Crash point: navigate_next → remove_children → load_chapter →
  ward_arr_alloc → ward_file_read → ward_decompress
- Synthetic EPUBs with ~3-5KB chapters: NO crash
- Conan EPUB with ~9-21KB chapters: ALWAYS crashes
- Standalone malloc(4097): NO crash
- All 5 Playwright viewports crash identically

APPROACH:
Phase 1: Instrument bridge to record all WASM export calls + import
         return values during the crash sequence. Run in CI to capture trace.
Phase 2: Replay the trace via wasm2c + ASan to find the corruption.
Phase 3: Minimize the ATS2 code to the smallest trigger.

---

EXPERIMENT 1: Instrument bridge for call trace
Status: DONE

First attempt failed: WebAssembly.Instance.exports properties are frozen
(non-writable). Assigning wrapper functions silently fails.

Fix: Wrap imports in-place (WASM→JS calls), create plain wrapper object
for exports (same pattern as bridge.js wrapExports), return fake result
from intercepted WebAssembly.instantiate.

Result: Captured 135-137 trace entries per viewport. Full crash sequence:
  ward_node_init → IDB → UI → file_import → ZIP reads → decompress(2x) →
  library display → book card click → reader UI → cover chapter →
  NEXT click → REMOVE_CHILDREN → decompress large chapter → parse HTML →
  ward_dom_flush(1119008, 21452) → CRASH

Key finding: crash point varies by 2 operations between viewports:
  - Viewport 2: crashes DURING ward_dom_flush(1119008, 21452)
  - Viewport 3: flush SUCCEEDS, then crashes during ward_js_file_read
  Non-deterministic timing → suggests renderer process crash, not WASM trap

---

EXPERIMENT 2: crash_repro.dats exerciser
Status: DONE — no crash in Node.js

Built crash_repro.dats matching the exact allocation pattern from trace:
  Phase 1: ZIP buffer (65558 bytes oversized alloc/free)
  Phase 2: Multiple DOM stream cycles (262144 bytes each)
  Phase 3: Decompress metadata (177, 252, 1028, 2725 alloc/free)
  Phase 4: Cover chapter (15 elements, SAX buffer alive during render)
  Phase 5: REMOVE_CHILDREN + 500 elements with text-wrapping allocs
  Phase 6: Post-render image loading allocs (30 + 5000 bytes)

Result: Runs successfully in Node.js/jsdom.
  - 669 nodes, 500 children, 8182 bytes innerHTML
  - No errors, no crashes

---

EXPERIMENT 3: wasm2c + AddressSanitizer
Status: DONE — NO corruption detected

Converted crash_repro.wasm to C via wasm2c, compiled with -fsanitize=address,
ran with stub imports that parse the DOM diff buffer.

Result: PASSED. ASan found no violations.
  - No heap-buffer-overflow
  - No use-after-free
  - No double-free
  - No stack-buffer-overflow
  - ward_dom_flush(133056, 13843): 1168 ops parsed correctly
  - Stack pointer balanced: 67440 before and after

---

EXPERIMENT 4: Linear memory stack analysis
Status: DONE — no stack overflow possible

Compared crash_repro.wasm (0 functions use linear memory stack) vs
quire.wasm (10 functions use linear memory stack).

quire functions using __stack_pointer:
  - loop_204, loop_280: 16-byte frames (render_tree loops)
  - load_chapter_448: 48-byte frame
  - __patsfun_514, __patsfun_516: 32-byte frames (closure calls)
  - __patsfun_455, __patsfun_471: 16-byte frames

Max depth: HTML nesting ~20 levels × 16 bytes = 320 bytes. With 1MB stack,
this cannot overflow.

---

EXPERIMENT 5: Ward exerciser in Chromium (pending)
Status: PENDING — waiting for CI

Created crash_repro.html that loads crash_repro.wasm via ward_bridge.mjs
in a real browser. Added e2e test to check if the exerciser alone
crashes Chromium.

Hypothesis: If crash_repro crashes Chromium → it's a ward bug.
            If it doesn't → the bug is in quire-specific code, not ward.

---

CONCLUSIONS SO FAR:
1. The WASM heap allocator is correct (ASan-verified)
2. No stack overflow is possible (tiny frames, bounded depth)
3. All buffer writes are bounds-checked by ATS2 dependent types
4. The crash is Chromium-renderer-specific (doesn't happen in Node.js)
5. Crash timing is non-deterministic (varies 2 ops between viewports)
6. No memory.grow during crash sequence (16MB initial is sufficient)

Strong evidence: the crash is NOT a ward WASM bug. It's either:
  (a) A Chromium/V8/Blink bug triggered by rapid DOM manipulation
  (b) A bug in ward_bridge.mjs's wardDomFlush JS implementation
  (c) A quire-specific bug in application code (not reproducible in exerciser)

Experiment 5 will determine (a)/(b) vs (c).
